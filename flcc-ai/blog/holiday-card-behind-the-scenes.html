
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Holiday Greetings - Behind the Scenes</title>
    <link rel="icon" type="image/x-icon" href="/images/HubLogo.png">
    
    <meta name="date" content="2025-12-14">
    <meta name="description" content="FLCC's video used AI (Nano Banana, Veo3, Flow) as an accelerator. Human expertise fixed its limits: consistency, door issues, and audio/timing (ADR). AI is an accelerator, not autopilot.">
    <meta name="thumbnail" content="articles/images/bts-over-the-shoulder-paul-jeff.png">


    <link rel="stylesheet" href="../articles/css/styles.css">
    
    <style>
        /* Simple article container to keep text readable */
        .article-container {
            max-width: 800px;
            margin: 0 auto;
            padding: 2rem 1rem;
            line-height: 1.6;
        }
        
        .article-header {
            margin-bottom: 2rem;
            border-bottom: 1px solid #eee;
            padding-bottom: 1rem;
        }

        .article-meta {
            color: #666;
            font-size: 0.9rem;
            margin-top: 0.5rem;
        }

        .article-content h2 {
            margin-top: 2rem;
            color: #333;
        }

        /* Match your button styles or use this simple one */
        .back-link {
            display: inline-block;
            margin-top: 2rem;
            text-decoration: none;
            color: #0056b3; /* Adjust to your brand blue */
        }
    </style>
</head>
<body>

    <header>
        <div class="nav-container">
            <div class="logo-area">
                <img src="../images/HubLogo.png" alt="FLCC FLX AI Hub Logo" class="logo">
                <div class="branding">
                    <span class="site-title">FLX AI Hub</span>
                    <span class="site-subtitle">INNOVATE & EDUCATE</span>
                </div>
            </div>
            
            <nav>
                <ul>
                    <li><a href="../index.html">Home</a></li>
                    <li><a href="../index.html#presentations">Presentations</a></li>
                    <li><a href="../index.html#resources">Resources</a></li>
                    <li><a href="../index.html#contact">Stay Informed</a></li>
                </ul>
            </nav>
        </div>
    </header>

    <main class="article-container">
        <article>
            <header class="article-header">
                <h1>Holiday Card - Behind the Scenes</h1>
                <div class="article-meta">
                    <span>Published on December 14, 2025</span> • 
                    <span>By Dave Ghidiu</span>
                </div>
            </header>
            
            <div class="article-content">
                <img src="../articles/images/bts-over-the-shoulder-paul-jeff.png" alt="Looking over the shoulder of Paul and Jeff as they work on the Holiday Greeting" style="width:100%; height:auto; border-radius:8px; margin-bottom:1rem;">

                <!--<p class="lead">Introductory text...</p>-->
                <!--<p>Main content goes here...</p>-->
            </div>            

            <div class="article-content">
                <!--<p class="lead">-->
                <!--    This is the introductory paragraph. It’s a great place to summarize what this "one-off" article is about.-->
                <!--</p>-->

                <!--<h2>How This Year’s Holiday Video Came to Life</h2>-->
                
                <p>At first glance, <a href="https://www.youtube.com/watch?v=HDEq6fLejOA" target="_blank">this year’s holiday video</a> feels almost effortless. The characters are charming, the style is nostalgic, and the whole thing carries the warmth of classic claymation holiday specials many of us grew up with. It’s easy to watch it and think, “Wow! I can't believe AI did this.”</p>
                <p>In an important way, that’s true. But the real story is much more human.</p>
                <p>It began when President Nye expressed interest in including an AI-generated element in his annual holiday greeting to the college community. Not as a novelty, but as a genuine creative experiment. That single question - <em>could AI be part of this year’s message?</em> - set everything else in motion.</p>
                <p>From there, Jim Perri (Visual and Performing Arts), who brings a rich background in screenwriting and theatrical production, wrote a highly descriptive screenplay. This turned out to be one of the most important decisions in the entire process! The script went far beyond dialogue; it described environments, actions, pacing, transitions, and visual intent. Those non-dialogue details mattered immensely. AI video tools don’t just respond to what characters say - they respond to what’s happening. Jim’s screenplay gave the AI something concrete to work with, shaping scenes in ways a dialogue-only script never could.</p>
                
                <img src="../articles/images/bts-jims-screenplay.png" alt="Looking over the shoulder of Paul and Jeff as they work on the Holiday Greeting" style="width:100%; height:auto; border-radius:8px; margin-bottom:1rem;">
                <p class="caption">The first step in any video production is a well-crafted script. Jim's screenplay was very descriptive (which was a great help when working with AI).</p>
                
                <p>With a script in hand, the team needed to answer a basic question: was this even feasible? Using Nano Banana, an image of President Nye was transformed into a whimsical, claymation-style “head elf.” That single image immediately captured the nostalgic stop-motion feel everyone hoped for.</p>
                
                <img src="../articles/images/bts-side-by-side.png" alt="Dr. Nye on the left, AI generated elf on the right" style="width:100%; height:auto; border-radius:8px; margin-bottom:1rem;">
                <p class="caption"><strong>Prompt:</strong> Google Gemini 3 Pro using Nano Banana<br /><code>Transform into a claymation elf</code></p>

                <p>From there, Google Veo3 and Google Flow were used to generate a few short video segments as a proof of concept. These early clips weren’t polished, but they worked well enough to show the idea had legs.</p>

                <img src="../articles/images/bts-video-proof-of-concept.png" alt="Thumbnails of AI video based on the AI generated elf." style="width:100%; height:auto; border-radius:8px; margin-bottom:1rem;">
                <p class="caption"><strong>Prompt:</strong> Google Veo3 in Google Flow<br /><code>We see the HEAD ELF seated behind his desk, which is piled with papers and reports, another of which HE is examining. He drops it to the desk, pulls his spectacles off and rubs the bridge of his nose with his thumb and forefinger. HEAD ELF says, "It’s days like this that make being a Subordinate Claus especially challenging."</code></p>

                <p>High off the fumes of a successful proof of concept, it was off to the races with Paul Engin and Jeff Kidd (Visual and Performing Arts) - the FLCC experts at video production.</p>
                <p>What followed looked far less like “prompt and done” and far more like a traditional animation and video production pipeline - just with AI woven throughout. However, as production ramped up, the challenges began to reveal themselves.</p>
                <p>One of the first hurdles was "character consistency". AI video tools generate short clips, often only a few seconds long, and across multiple clips the look of individual characters tend to drift. Facial proportions shift. Eyes change. Small details (like glasses) appear and disappear. Characters changed radically (theYeti had a carrot nose at one point and AI injected a bumble bee at another point):</p>

                <img src="../articles/images/bts-ai-outtakes.png" alt="" style="width:100%; height:auto; border-radius:8px; margin-bottom:1rem;">
                <p class="caption">It was evident early on that character consistency was going to bee a problem.</p>

                <p>To solve this, Paul relied on a classic animation technique: character sheets. Multiple reference images of each character were created and reused to anchor the AI visually and keep characters recognizable from scene to scene. It was a decades-old practice paired with modern tools.</p>
                
                <img src="../articles/images/bts-character-sheet.png" alt="AI generated character sheet (or 'turnaround') based on an AI generated image of an elf." style="width:100%; height:auto; border-radius:8px; margin-bottom:1rem;">
                <p class="caption"><strong>Prompt:</strong> Google Gemini 3 Pro using Nano Banana<br /><code>Can you create a character turnaround from the attached image</code></p>

                <p>Other challenges were more stubborn. At one point, characters needed to appear in a room without opening a door. No matter how clearly Paul crafted the instructions, the AI insisted on opening the door.</p>
                
                <img src="../articles/images/bts-door-keeps-opening.png" alt="Smoke exploding through the opening of swinging doors." style="width:100%; height:auto; border-radius:8px; margin-bottom:1rem;">
                <p class="caption"><strong>Prompt:</strong> Google Veo3 in Google Flow<br /><code>From out of nowhere a buff of smoke made of snow and snowflakes appears and the characters all pop into frame from the snow. The door can stay closed.</code><br /><br />The door did not, in fact, stay closed.</p>

                <p>The workaround wasn’t a better prompt - it was an old filmmaking trick. Using Photoshop, Paul took a still of the elves and put them in front of a "blue screen" and then had AI generate their entrance in a puff of smoke. Paul then had to manually composite them into the scene using Adobe After Effects and Premiere. By removing the door from the AI’s “world,” the problem disappeared.</p>
                
                <img src="../articles/images/bts-blue-screen.png" alt="Using Adobe software to add in the background to characters in front of a blue screen." style="width:100%; height:auto; border-radius:8px; margin-bottom:1rem;">
                <p class="caption">Putting the characters on a blue screen was the only way to close the issue of the door.</p>
                
                <p>Directing performance proved just as tricky. Getting characters to look in the right direction, react naturally, or take turns speaking reliably was difficult. AI struggled with multi-character dialogue, often moving the wrong mouths at the wrong time or having everyone speak at once. At other times, the voice of one character would change to a different voice. After wrestling with AI to solve the problem of multiple speakers (with careful prompting), another issue surfaced - the video was too long.</p>
                <p>Jeff sped up the video to 1.25 times the normal speed to tighten the length of the video. Of course, the speech that AI had generated with the videos was now out of whack - but that is okay because Jeff and Paul knew that they would have to record all the voices with voice actors anyhow. The dialogue was re-recorded (by voice actors at the College) and synced by hand, a process known as ADR, giving full control over timing, clarity, and tone.</p>
                <p>Audio presented its own set of surprises. Each AI-generated clip came with different background music, sound effects, and volume levels. Rather than accept that inconsistency, voice tracks were cleaned using AI audio tool ElevenLabs and music was generated separately and applied consistently across the entire video. AI helped here - but only after people decided what the soundscape should feel like.</p>
                <p>Throughout the process, the pattern repeated itself. AI would get the team 80 or 90 percent of the way there, and then niche human experience would take over. Framing was adjusted. Scenes were cropped. Timing was refined. Visuals were composited and polished using traditional editing tools. What made the video work wasn’t that AI was flawless. It was that every time it wasn’t, people knew what to do next. They had the vision from the beginning and they had the experience to realize that vision when AI had hit its limits.</p>
                <p>In the end, this video wasn’t made by AI alone. It was made by writers, animators, editors, and sound designers using AI as an accelerator rather than an autopilot. AI made something like this possible on a tight timeline. Human skill made it coherent, expressive, and finished.</p>
                <p>If this behind-the-scenes look changes how you think about AI, that’s a good thing. The technology is impressive - but it shines brightest when paired with experience, judgment, and care. And perhaps the most exciting part is this: this is the worst these tools will ever be.</p>
                <p>Happy holidays from all of us at FLCC, and thanks for taking a moment to look behind the curtain.</p>

            </div>
        </article>

        <a href="../index.html" class="back-link">&larr; Back to Home</a>
    </main>

    <footer>
        <div class="footer-content">
            <div class="footer-branding">
                <span class="site-title">FLX AI Hub</span>
            </div>
            <p class="copyright">
                &copy; 2024 The FLX AI Hub. All rights reserved.
            </p>
        </div>
    </footer>

<script defer src="https://static.cloudflareinsights.com/beacon.min.js/vcd15cbe7772f49c399c6a5babf22c1241717689176015" integrity="sha512-ZpsOmlRQV6y907TI0dKBHq9Md29nnaEIPlkf84rnaERnq6zvWvPUqr2ft8M1aS28oN72PdrCzSjY4U6VaAw1EQ==" data-cf-beacon='{"version":"2024.11.0","token":"1f4307355f984a529a180c0bd298a86a","r":1,"server_timing":{"name":{"cfCacheStatus":true,"cfEdge":true,"cfExtPri":true,"cfL4":true,"cfOrigin":true,"cfSpeedBrain":true},"location_startswith":null}}' crossorigin="anonymous"></script>
</body>
</html>